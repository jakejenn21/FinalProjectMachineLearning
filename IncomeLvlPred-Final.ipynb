{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (25000, 14) | Test shape: (23842, 14) | Submission shape: (23842, 2)\n",
      "\n",
      "    age         workclass    education  education.num      marital.status  \\\n",
      "0   53  Self-emp-not-inc  Prof-school             15  Married-civ-spouse   \n",
      "1   33  Self-emp-not-inc    Bachelors             13  Married-civ-spouse   \n",
      "2   47           Private      HS-grad              9  Married-civ-spouse   \n",
      "3   40           Private      HS-grad              9            Divorced   \n",
      "4   39           Private      HS-grad              9  Married-civ-spouse   \n",
      "\n",
      "         occupation    relationship                race     sex  capital.gain  \\\n",
      "0    Prof-specialty         Husband  Asian-Pac-Islander    Male             0   \n",
      "1   Exec-managerial         Husband               White    Male             0   \n",
      "2      Craft-repair         Husband               White    Male             0   \n",
      "3      Craft-repair  Other-relative               White  Female             0   \n",
      "4  Transport-moving         Husband               White    Male             0   \n",
      "\n",
      "   capital.loss  hours.per.week native.country  income>50K  \n",
      "0             0              40          India           1  \n",
      "1             0              40  United-States           1  \n",
      "2             0              40  United-States           0  \n",
      "3             0              40        Vietnam           0  \n",
      "4             0              50  United-States           0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='income>50K', ylabel='count'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, preprocessing\n",
    "\n",
    "\n",
    "# X Train\n",
    "traindf = pd.read_csv(\"in-csv/train_final.csv\")\n",
    "# X Test\n",
    "testdf = pd.read_csv(\"in-csv/test_final.csv\")\n",
    "\n",
    "#try dropping fnlwgt\n",
    "traindf = traindf.drop('fnlwgt', axis=1)\n",
    "testdf = testdf.drop('fnlwgt', axis=1)\n",
    "\n",
    "# X Sample\n",
    "sampledf = pd.read_csv(\"in-csv/sample_final.csv\")\n",
    "\n",
    "\n",
    "# -----------Data Exploration-------------\n",
    "\n",
    "print(f'Train shape: {traindf.shape}',\n",
    "      f'Test shape: {testdf.shape}',\n",
    "      f'Submission shape: {sampledf.shape}', sep=' | ')\n",
    "\n",
    "print(\"\\n\", traindf.head())\n",
    "\n",
    "sns.countplot(traindf.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "      <th>num_of_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>workclass</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>education</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>education.num</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marital.status</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>occupation</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>relationship</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>race</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sex</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>capital.gain</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>capital.loss</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hours.per.week</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>native.country</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>income&gt;50K</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           columns  num_of_unique\n",
       "0              age             73\n",
       "1        workclass              9\n",
       "2        education             16\n",
       "3    education.num             16\n",
       "4   marital.status              7\n",
       "5       occupation             15\n",
       "6     relationship              6\n",
       "7             race              5\n",
       "8              sex              2\n",
       "9     capital.gain            117\n",
       "10    capital.loss             89\n",
       "11  hours.per.week             92\n",
       "12  native.country             41\n",
       "13      income>50K              2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View uniques values of train data\n",
    "\n",
    "traindf.index.nunique(), len(traindf.index)\n",
    "\n",
    "traindf.head()\n",
    "\n",
    "nunique_vals = list()\n",
    "\n",
    "for column in traindf:\n",
    "    nunique_vals.append(traindf[column].nunique())\n",
    "    \n",
    "pd.DataFrame({'columns': traindf.columns,\n",
    "              'num_of_unique': nunique_vals})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "      <th>num_of_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>workclass</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>education</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>education.num</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marital.status</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>occupation</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>relationship</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>race</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sex</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>capital.gain</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>capital.loss</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hours.per.week</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>native.country</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>income&gt;50K</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           columns  num_of_unique\n",
       "0              age             74\n",
       "1        workclass              9\n",
       "2        education             16\n",
       "3    education.num             16\n",
       "4   marital.status              7\n",
       "5       occupation             15\n",
       "6     relationship              6\n",
       "7             race              5\n",
       "8              sex              2\n",
       "9     capital.gain            123\n",
       "10    capital.loss             99\n",
       "11  hours.per.week             96\n",
       "12  native.country             42\n",
       "13      income>50K              2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# View uniques values of train and test data\n",
    "\n",
    "all_df = pd.concat([traindf, testdf], axis=0, ignore_index=True)\n",
    "\n",
    "all_df.index.nunique(), len(all_df.index)\n",
    "\n",
    "all_df = all_df.drop('ID', axis=1)\n",
    "\n",
    "all_df.head()\n",
    "\n",
    "nunique_vals = list()\n",
    "\n",
    "for column in all_df:\n",
    "    nunique_vals.append(all_df[column].nunique())\n",
    "    \n",
    "pd.DataFrame({'columns': all_df.columns,\n",
    "              'num_of_unique': nunique_vals})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics fot column: age\n",
      "Column unique values:\n",
      " [53 33 47 40 39 55 22 27 37 79 31 19 21 56 26 42 30 35 68 38 34 32 72 24\n",
      " 50 28 49 29 51 48 41 66 60 20 76 45 52 18 44 59 75 71 46 23 17 54 36 25\n",
      " 57 43 58 64 61 70 90 81 85 62 65 69 67 80 63 77 78 73 84 74 88 83 82 87\n",
      " 89 86]\n",
      "Number of unique values: 74\n",
      "Number of NAN values: 0\n",
      "__________________________________________________\n",
      "Statistics fot column: workclass\n",
      "Column unique values:\n",
      " ['Self-emp-not-inc' 'Private' 'Federal-gov' 'Local-gov' 'Self-emp-inc' '?'\n",
      " 'State-gov' 'Never-worked' 'Without-pay']\n",
      "Number of unique values: 9\n",
      "Number of NAN values: 0\n",
      "__________________________________________________\n",
      "Statistics fot column: education\n",
      "Column unique values:\n",
      " ['Prof-school' 'Bachelors' 'HS-grad' 'Doctorate' 'Masters' 'Some-college'\n",
      " '11th' '12th' '5th-6th' 'Assoc-acdm' '9th' 'Preschool' 'Assoc-voc'\n",
      " '7th-8th' '10th' '1st-4th']\n",
      "Number of unique values: 16\n",
      "Number of NAN values: 0\n",
      "__________________________________________________\n",
      "Statistics fot column: education.num\n",
      "Column unique values:\n",
      " [15 13  9 16 14 10  7  8  3 12  5  1 11  4  6  2]\n",
      "Number of unique values: 16\n",
      "Number of NAN values: 0\n",
      "__________________________________________________\n",
      "Statistics fot column: marital.status\n",
      "Column unique values:\n",
      " ['Married-civ-spouse' 'Divorced' 'Never-married' 'Married-spouse-absent'\n",
      " 'Widowed' 'Separated' 'Married-AF-spouse']\n",
      "Number of unique values: 7\n",
      "Number of NAN values: 0\n",
      "__________________________________________________\n",
      "Statistics fot column: occupation\n",
      "Column unique values:\n",
      " ['Prof-specialty' 'Exec-managerial' 'Craft-repair' 'Transport-moving'\n",
      " 'Other-service' 'Machine-op-inspct' 'Adm-clerical' 'Sales'\n",
      " 'Handlers-cleaners' '?' 'Farming-fishing' 'Tech-support'\n",
      " 'Priv-house-serv' 'Protective-serv' 'Armed-Forces']\n",
      "Number of unique values: 15\n",
      "Number of NAN values: 0\n",
      "__________________________________________________\n",
      "Statistics fot column: relationship\n",
      "Column unique values:\n",
      " ['Husband' 'Other-relative' 'Unmarried' 'Not-in-family' 'Own-child' 'Wife']\n",
      "Number of unique values: 6\n",
      "Number of NAN values: 0\n",
      "__________________________________________________\n",
      "Statistics fot column: race\n",
      "Column unique values:\n",
      " ['Asian-Pac-Islander' 'White' 'Black' 'Other' 'Amer-Indian-Eskimo']\n",
      "Number of unique values: 5\n",
      "Number of NAN values: 0\n",
      "__________________________________________________\n",
      "Statistics fot column: sex\n",
      "Column unique values:\n",
      " ['Male' 'Female']\n",
      "Number of unique values: 2\n",
      "Number of NAN values: 0\n",
      "__________________________________________________\n",
      "Statistics fot column: capital.gain\n",
      "Column unique values:\n",
      " [    0 15024  7298 15020 99999  4865  7688  3325  3456  4386   594  1506\n",
      " 10605  3464 27828  3432  3137  4787  5178  8614  5013  1086  2635  9386\n",
      "  3103  1848  5721  2174  1639  2407  2414  1831  4650  2829  4416  2346\n",
      "   914  2580  4508 20051  2885  3471  4064  2329  2062  3908  5556  4101\n",
      "  1055  5455  3781  6418  2176 10520 14344  1151  1797  2463 34095  6849\n",
      " 25236  3818  3273  3942  2538 14084  7430  2009  1424  2354 15831   114\n",
      "  7896  2961  7443  2964  3674 13550  6497  2597  9562  4934  2228  2202\n",
      "  3411  1455  5060  2050  3418  4931 18481  1264  2907  2653  2977  3887\n",
      "  1173  2105  2936  6514 25124  1409   991  2036  1471 11678  6767   401\n",
      "  6097  6723  7978  2290 41310  4687  2993  6360 10566 22040  1111  7262\n",
      "  6612  2387  1731]\n",
      "Number of unique values: 123\n",
      "Number of NAN values: 0\n",
      "__________________________________________________\n",
      "Statistics fot column: capital.loss\n",
      "Column unique values:\n",
      " [   0 1721 2258 1510 1980 1887 1741  625 2206 1579 1564 1902 4356 2205\n",
      " 1719 2057 1876 2392 1977 2415 1485 1848 1602 1590 1594 1740 2377 2559\n",
      " 1672 2824 1380 2051 1617 1504 2444 1092 1628 2001 2339 2179 1408 2231\n",
      " 3683 1411 1668 2042 1974 2352 1726 1844 2603  880 2149 2002 1573 1651\n",
      " 2129 1762 2282 1669  419 1825 2174 1429  213 1911 2457 2080 2472 3175\n",
      " 1816 2238 3004 1944 1421  653 1340 3770 1258 1735 2246  974 1648 2754\n",
      "  810  323 2267 2547 1138 2163 2467 1755 1870 3900 2465 1539  155 2489\n",
      " 2201]\n",
      "Number of unique values: 99\n",
      "Number of NAN values: 0\n",
      "__________________________________________________\n",
      "Statistics fot column: hours.per.week\n",
      "Column unique values:\n",
      " [40 50 60 45 35 41  7 24 15 48 25 36 28 56 20 70 30 42 65 46 10 44  8 63\n",
      " 54 16 55 72 86  5 12  6 43 38 80 27 32 52 49 37 33 34 99 18 75 53 22  4\n",
      " 14 62 26 21 47  2 11  3 90 19 88 66 23 17 84 57 39 82 58  9 85 61 76  1\n",
      " 98 89 78 51 31 94 64 29 96 97 68 73 13 95 77 92 91 59 69 74 67 81 79 87]\n",
      "Number of unique values: 96\n",
      "Number of NAN values: 0\n",
      "__________________________________________________\n",
      "Statistics fot column: native.country\n",
      "Column unique values:\n",
      " ['India' 'United-States' 'Vietnam' 'England' 'Mexico' '?' 'Guatemala'\n",
      " 'Iran' 'Laos' 'Germany' 'Thailand' 'Ireland' 'Philippines' 'Hong' 'China'\n",
      " 'Dominican-Republic' 'Scotland' 'Haiti' 'Cuba' 'Jamaica' 'Peru' 'Canada'\n",
      " 'Cambodia' 'Italy' 'Poland' 'Yugoslavia' 'El-Salvador' 'Columbia'\n",
      " 'Greece' 'Ecuador' 'Japan' 'South' 'Puerto-Rico' 'Nicaragua'\n",
      " 'Outlying-US(Guam-USVI-etc)' 'Taiwan' 'Honduras' 'Trinadad&Tobago'\n",
      " 'Portugal' 'Hungary' 'France' 'Holand-Netherlands']\n",
      "Number of unique values: 42\n",
      "Number of NAN values: 0\n",
      "__________________________________________________\n",
      "Statistics fot column: income>50K\n",
      "Column unique values:\n",
      " [ 1.  0. nan]\n",
      "Number of unique values: 3\n",
      "Number of NAN values: 23842\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN Values\n",
    "\n",
    "for column in all_df.columns:\n",
    "\n",
    "    unique_values = all_df[column].unique()\n",
    "    \n",
    "    print(f'Statistics fot column: {column}')\n",
    "    print(f'Column unique values:\\n {unique_values}')\n",
    "    print(f'Number of unique values: {len(unique_values)}')\n",
    "    print(f'Number of NAN values: {all_df[column].isna().sum()}')\n",
    "    #print(f'Number of ? values: {all_df.iloc[(all_df[column]==\"?\")].sum()}')\n",
    "    print('_' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d62df93093d4f779584ff615b0d5fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "\"['fnlwgt'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dn/nlt677wd5sb6q9mrpms5syfw0000gn/T/ipykernel_49738/2086968848.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mall_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'income>50K'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'income>50K'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mall_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontinuous\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontinuous\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3462\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3464\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['fnlwgt'] not in index\""
     ]
    }
   ],
   "source": [
    "#Change missing values\n",
    "def replace_missing(data):\n",
    "    for col in data.columns:\n",
    "        majority_class_index = np.argmax(np.unique(data[col], return_counts=True)[1])\n",
    "        majority_value = np.unique(data[col])[majority_class_index]\n",
    "        if majority_value == \"?\":\n",
    "          newdata = data[data[col] != \"?\"]\n",
    "          majority_class_index = np.argmax(np.unique(newdata[col], return_counts=True)[1])\n",
    "          majority_value = np.unique(newdata[col])[majority_class_index]\n",
    "\n",
    "        data[col] = np.where(data[col] == \"?\", majority_value, data[col])\n",
    "\n",
    "\n",
    "replace_missing(all_df)\n",
    "\n",
    "# Features encoding\n",
    "\n",
    "# Possibly drop fnlwgt???\n",
    "#all_df = all_df.drop('fnlwgt', axis=1)\n",
    "\n",
    "categorical = ['workclass', 'education', 'marital.status', 'occupation',\n",
    "               'relationship', 'race', 'sex', 'native.country']\n",
    "\n",
    "continuous = ['age','fnlwgt','education.num','capital.gain','capital.loss','hours.per.week']\n",
    "\n",
    "\n",
    "\n",
    "# Use LabelEncoding to change string values to numbers\n",
    "\n",
    "features = [x for x in all_df.columns \n",
    "            if x not in ['ID', 'income>50K'] + continuous]\n",
    "\n",
    "for feat in tqdm(features):\n",
    "    lbl_enc = preprocessing.LabelEncoder()\n",
    "    \n",
    "    all_df[feat] = lbl_enc.fit_transform(all_df[feat]. \\\n",
    "                                         fillna('-1'). \\\n",
    "                                         astype(str).values)\n",
    "    \n",
    "all_df['income>50K'] = all_df['income>50K'].fillna(-1)\n",
    "all_df[continuous] = all_df[continuous].fillna(-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print Information\n",
    "\n",
    "all_df.head()\n",
    "\n",
    "all_df.shape\n",
    "\n",
    "all_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (25000, 15) | Test shape: (23842, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[    53,      5,  93449, ...,      0,     40,     18],\n",
       "        [    33,      5, 123424, ...,      0,     40,     38],\n",
       "        [    47,      3, 144844, ...,      0,     40,     38],\n",
       "        ...,\n",
       "        [    39,      3, 225544, ...,      0,     40,     30],\n",
       "        [    53,      3, 346871, ...,      0,     46,     38],\n",
       "        [    18,      3, 192321, ...,      0,     40,     38]]),\n",
       " array([1., 1., 0., ..., 0., 1., 0.]),\n",
       " array([[    33,      5, 222162, ...,      0,     40,     38],\n",
       "        [    68,      3,  29240, ...,      0,     12,     38],\n",
       "        [    34,      3, 103596, ...,      0,     40,     38],\n",
       "        ...,\n",
       "        [    67,      4, 182581, ...,      0,     20,     38],\n",
       "        [    46,      1, 274689, ...,      0,     40,     38],\n",
       "        [    66,      0,  47358, ...,      0,     40,     38]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare Data for Training and Testing\n",
    "\n",
    "train = all_df[:traindf.shape[0]]\n",
    "test = all_df[traindf.shape[0]:]\n",
    "\n",
    "print(f'Train shape: {train.shape}',\n",
    "      f'Test shape: {test.shape}', sep=' | ')\n",
    "\n",
    "train.isna().sum().sum(), test.isna().sum().sum() \n",
    "\n",
    "train_data = train.drop('income>50K', axis=1).to_numpy()\n",
    "train_target = train['income>50K'].to_numpy()\n",
    "\n",
    "test_data = test.drop('income>50K', axis=1).to_numpy()\n",
    "\n",
    "categorical = all_df.drop(['income>50K'] + continuous,\n",
    "                          axis=1).columns\n",
    "\n",
    "cat_cols_idx, cont_cols_idx = list(), list()\n",
    "\n",
    "for idx, column in enumerate(all_df.drop('income>50K',\n",
    "                                         axis=1).columns):\n",
    "    if column in categorical:\n",
    "        cat_cols_idx.append(idx)\n",
    "    elif column in continuous:\n",
    "        cont_cols_idx.append(idx)\n",
    "\n",
    "train_data, train_target, test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, hidden_width, depth):\n",
    "        super(NN, self).__init__()\n",
    "        layers = []\n",
    "        input_layer = nn.Linear(14, hidden_width)\n",
    "        \n",
    "        activation_input = nn.Sigmoid()\n",
    "        #activation_input = nn.Threshold()\n",
    "        #activation_input = nn.Tanh()\n",
    "        #activation_input = nn.ReLU()\n",
    "\n",
    "        layers.append(input_layer)\n",
    "        layers.append(activation_input)\n",
    "        for i in range(depth-1):\n",
    "            hidden_layer = nn.Linear(hidden_width, hidden_width)\n",
    "            activation_hidden = nn.Sigmoid()\n",
    "            #activation_hidden = nn.Threshold()\n",
    "            #activation_hidden = nn.Tanh()\n",
    "            #activation_hidden = nn.ReLU()\n",
    "\n",
    "            layers.append(hidden_layer)\n",
    "            layers.append(activation_hidden)\n",
    "\n",
    "        output_layer = nn.Linear(hidden_width, 1)\n",
    "        output_layer2 = nn.Sigmoid()\n",
    "        layers.append(output_layer)\n",
    "        layers.append(output_layer2)\n",
    "\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "        def init_weights(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "\n",
    "        self.model.apply(init_weights)\n",
    "\n",
    "    def forward(self, X):\n",
    "        input = np.float32(X)\n",
    "        out = torch.from_numpy(input)\n",
    "        out.requires_grad = True\n",
    "        return self.model(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training/Testing:\n",
      "\n",
      "width: 5, depth:3, roc_auc_score: 0.474531131619236\n",
      "width: 5, depth:5, roc_auc_score: 0.410141544342212\n",
      "width: 5, depth:9, roc_auc_score: 0.4959275265957447\n",
      "width: 10, depth:3, roc_auc_score: 0.5506401168383118\n",
      "width: 10, depth:5, roc_auc_score: 0.4640368344899624\n",
      "width: 10, depth:9, roc_auc_score: 0.4581766714523316\n",
      "width: 25, depth:3, roc_auc_score: 0.6261635682077741\n",
      "width: 25, depth:5, roc_auc_score: 0.4937841386657632\n",
      "width: 25, depth:9, roc_auc_score: 0.5230104186280047\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "\n",
    "print(\"\\nTraining/Testing:\\n\")\n",
    "\n",
    "depth = [3, 5, 9]\n",
    "width = [5, 10, 25]\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "for i in width:\n",
    "    for j in depth:\n",
    "        NeuralNet = NN(i, j)\n",
    "        optimizer = torch.optim.Adam(NeuralNet.parameters(), lr=0.0005)\n",
    "\n",
    "        for t in range(25):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass: compute predicted y by passing x to the model.\n",
    "            y_train_pred_tensor = NeuralNet.forward(train_data).flatten()\n",
    "\n",
    "            y_train_np = np.float32(train_target)\n",
    "            y_train_tensor = torch.from_numpy(y_train_np)\n",
    "            y_train_tensor.requires_grad = True\n",
    "            y_train_tensor = y_train_pred_tensor.flatten()\n",
    "\n",
    "            loss = criterion(y_train_pred_tensor.flatten(), y_train_tensor)\n",
    "\n",
    "            # Backward pass: compute gradient of the loss with respect to model\n",
    "            loss.backward()\n",
    "\n",
    "            # Calling the step function on an Optimizer makes an update to its parameters\n",
    "            optimizer.step()\n",
    "\n",
    "        #train error\n",
    "        train_pred = NeuralNet.forward(train_data)\n",
    "        train_pred = train_pred.detach().numpy().flatten()\n",
    "\n",
    "        print(f\"width: {i}, depth:{j}, roc_auc_score: {metrics.roc_auc_score(train_target, train_pred)}\")\n",
    "\n",
    "        #test predictions -> add to csv\n",
    "        test_pred = NeuralNet.forward(test_data)\n",
    "        test_pred = test_pred.detach().numpy().flatten()\n",
    "\n",
    "        nn_predictions_df = pd.DataFrame({'ID': sampledf['ID'], \n",
    "                                   'Prediction': test_pred})\n",
    "\n",
    "        nn_predictions_df.to_csv(\"out-csv/\" + \"width-\" + str(i) + \"-depth-\" + str(j) + \".csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/janalynjenn/Desktop/FinalProjectMachineLearning/nn-submissions.zip'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "shutil.make_archive('nn-submissions', 'zip', 'out-csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec8d95e24704cfab5e5b4db36ccad60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.8607538\tbest: 0.8607538 (0)\ttotal: 58.6ms\tremaining: 10m 44s\n",
      "300:\ttest: 0.9179078\tbest: 0.9179078 (300)\ttotal: 2.16s\tremaining: 1m 16s\n",
      "600:\ttest: 0.9201867\tbest: 0.9201873 (595)\ttotal: 3.77s\tremaining: 1m 5s\n",
      "900:\ttest: 0.9208915\tbest: 0.9208981 (893)\ttotal: 5.18s\tremaining: 58s\n",
      "1200:\ttest: 0.9217178\tbest: 0.9217178 (1195)\ttotal: 6.61s\tremaining: 53.9s\n",
      "1500:\ttest: 0.9224851\tbest: 0.9224873 (1490)\ttotal: 8.08s\tremaining: 51.1s\n",
      "1800:\ttest: 0.9228286\tbest: 0.9228497 (1779)\ttotal: 9.53s\tremaining: 48.7s\n",
      "2100:\ttest: 0.9231976\tbest: 0.9232024 (2091)\ttotal: 11s\tremaining: 46.6s\n",
      "2400:\ttest: 0.9234927\tbest: 0.9234927 (2398)\ttotal: 12.5s\tremaining: 44.8s\n",
      "2700:\ttest: 0.9238891\tbest: 0.9238943 (2685)\ttotal: 14.1s\tremaining: 43.3s\n",
      "3000:\ttest: 0.9241598\tbest: 0.9241598 (3000)\ttotal: 15.7s\tremaining: 41.8s\n",
      "3300:\ttest: 0.9244325\tbest: 0.9244384 (3286)\ttotal: 17.3s\tremaining: 40.3s\n",
      "3600:\ttest: 0.9246741\tbest: 0.9247015 (3489)\ttotal: 18.8s\tremaining: 38.7s\n",
      "3900:\ttest: 0.9251220\tbest: 0.9251255 (3881)\ttotal: 20.6s\tremaining: 37.6s\n",
      "4200:\ttest: 0.9252684\tbest: 0.9252888 (4122)\ttotal: 22.4s\tremaining: 36.3s\n",
      "4500:\ttest: 0.9256132\tbest: 0.9256543 (4413)\ttotal: 24.4s\tremaining: 35.2s\n",
      "4800:\ttest: 0.9258931\tbest: 0.9259055 (4793)\ttotal: 26.5s\tremaining: 34.2s\n",
      "5100:\ttest: 0.9262534\tbest: 0.9262536 (5099)\ttotal: 28.5s\tremaining: 32.9s\n",
      "5400:\ttest: 0.9264969\tbest: 0.9265024 (5399)\ttotal: 30.5s\tremaining: 31.6s\n",
      "5700:\ttest: 0.9267133\tbest: 0.9267179 (5657)\ttotal: 32.5s\tremaining: 30.2s\n",
      "6000:\ttest: 0.9268853\tbest: 0.9268892 (5987)\ttotal: 34.7s\tremaining: 28.9s\n",
      "6300:\ttest: 0.9270308\tbest: 0.9270308 (6300)\ttotal: 36.7s\tremaining: 27.3s\n",
      "6600:\ttest: 0.9271406\tbest: 0.9271493 (6596)\ttotal: 38.7s\tremaining: 25.8s\n",
      "6900:\ttest: 0.9270854\tbest: 0.9271530 (6679)\ttotal: 40.8s\tremaining: 24.2s\n",
      "7200:\ttest: 0.9270454\tbest: 0.9271530 (6679)\ttotal: 42.9s\tremaining: 22.6s\n",
      "7500:\ttest: 0.9272178\tbest: 0.9272191 (7497)\ttotal: 45.3s\tremaining: 21.1s\n",
      "7800:\ttest: 0.9271454\tbest: 0.9272191 (7497)\ttotal: 47.5s\tremaining: 19.5s\n",
      "8100:\ttest: 0.9271067\tbest: 0.9272191 (7497)\ttotal: 49.8s\tremaining: 17.8s\n",
      "8400:\ttest: 0.9271086\tbest: 0.9272191 (7497)\ttotal: 52.2s\tremaining: 16.1s\n",
      "8700:\ttest: 0.9271510\tbest: 0.9272191 (7497)\ttotal: 54.5s\tremaining: 14.4s\n",
      "9000:\ttest: 0.9271967\tbest: 0.9272191 (7497)\ttotal: 57s\tremaining: 12.7s\n",
      "9300:\ttest: 0.9272043\tbest: 0.9272191 (7497)\ttotal: 59.3s\tremaining: 10.8s\n",
      "9600:\ttest: 0.9271467\tbest: 0.9272261 (9326)\ttotal: 1m 1s\tremaining: 9.03s\n",
      "9900:\ttest: 0.9271517\tbest: 0.9272261 (9326)\ttotal: 1m 4s\tremaining: 7.18s\n",
      "10200:\ttest: 0.9271671\tbest: 0.9272261 (9326)\ttotal: 1m 7s\tremaining: 5.27s\n",
      "10500:\ttest: 0.9273246\tbest: 0.9273259 (10499)\ttotal: 1m 9s\tremaining: 3.32s\n",
      "10800:\ttest: 0.9272895\tbest: 0.9273620 (10570)\ttotal: 1m 12s\tremaining: 1.34s\n",
      "10999:\ttest: 0.9272822\tbest: 0.9273620 (10570)\ttotal: 1m 14s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.9273619605\n",
      "bestIteration = 10570\n",
      "\n",
      "Shrink model to first 10571 iterations.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cat Boost\n",
    "\n",
    "# X Train\n",
    "traindf = pd.read_csv(\"in-csv/train_final.csv\")\n",
    "# X Test\n",
    "testdf = pd.read_csv(\"in-csv/test_final.csv\")\n",
    "# X Sample\n",
    "sampledf = pd.read_csv(\"in-csv/sample_final.csv\")\n",
    "\n",
    "#try dropping fnlwgt\n",
    "# traindf = traindf.drop('fnlwgt', axis=1)\n",
    "# testdf = testdf.drop('fnlwgt', axis=1)\n",
    "\n",
    "X = traindf.drop('income>50K', axis=1)\n",
    "y = traindf['income>50K']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27)\n",
    "\n",
    "test_data = testdf.drop('ID', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cat_feats = ['workclass', 'education', 'marital.status', 'occupation',\n",
    "               'relationship', 'race', 'sex', 'native.country']\n",
    "\n",
    "best_params = {\n",
    "    'bagging_temperature': 0.8, \n",
    "    'depth': 5, \n",
    "    'iterations': 11000,\n",
    "    'l2_leaf_reg': 30,\n",
    "    'random_strength': 0.8\n",
    "}\n",
    "\n",
    "model_cat = CatBoostRegressor(**best_params,\n",
    "                                loss_function='RMSE',\n",
    "                                eval_metric='AUC', \n",
    "                                nan_mode='Min',\n",
    "                                random_seed=42,\n",
    "                                thread_count=4,\n",
    "                                verbose=True)\n",
    "\n",
    "model_cat.fit(X_train, y_train,\n",
    "              eval_set=(X_test, y_test), \n",
    "              cat_features=cat_feats,\n",
    "              verbose_eval=300, \n",
    "              use_best_model=True,\n",
    "              plot=True)\n",
    "\n",
    "\n",
    "#CatBoost predictions\n",
    "\n",
    "test_data = testdf.drop('ID', axis=1).to_numpy()\n",
    "\n",
    "cat_predictions = model_cat.predict(test_data)\n",
    "\n",
    "cat_predictions_df = pd.DataFrame({'ID': sampledf['ID'], \n",
    "                                   'Prediction': cat_predictions})\n",
    "\n",
    "cat_predictions_df.to_csv('catboost_res_sub.csv', index=False)\n",
    "                                \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
